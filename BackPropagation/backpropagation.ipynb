{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF2RxGXvzLrAQfzsGY+MdP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazimayaan/Machine-Learning-Lab/blob/main/backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H0EjgC7QeSzC"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputNeurons = 2\n",
        "HiddenLayerNeurons = 4\n",
        "outputNeurons = 2\n",
        "iteration = 6000\n",
        "\n",
        "input = np.random.randint(1,5,inputNeurons)\n",
        "output = np.array([1.0,0.0])\n",
        "hidden_layer = np.random.rand(1,HiddenLayerNeurons)\n",
        "\n",
        "hidden_bias = np.random.rand(1,HiddenLayerNeurons)\n",
        "output_bias=np.random.rand(1,outputNeurons)\n",
        "hiddenweights = np.random.rand(inputNeurons,HiddenLayerNeurons)\n",
        "outputweights = np.random.rand(HiddenLayerNeurons,outputNeurons)\n",
        "\n",
        "def sigmoid(layer):\n",
        "  return 1/(1+np.exp(-layer))\n",
        "\n",
        "def gradient(layer):\n",
        "  return layer*(1-layer)\n",
        "\n",
        "for i in range(iteration):\n",
        "\n",
        "  hiddenlayer= np.dot(input,hiddenweights)\n",
        "  hiddenlayer = sigmoid(hiddenlayer+hidden_bias)\n",
        "\n",
        "  outputlayer = np.dot(hiddenlayer,outputweights)\n",
        "  outputlayer = sigmoid(outputlayer+output_bias)\n",
        "\n",
        "  error = (output-outputlayer)\n",
        "  gradient_outputl = gradient(outputlayer)\n",
        "\n",
        "  error_terms_output = gradient_outputl*error\n",
        "  error_terms_hidden = gradient(hiddenlayer)*np.dot(error_terms_output,outputweights.T)\n",
        "\n",
        "  gradient_hidden_weights = np.dot(input.reshape(inputNeurons,1),error_terms_hidden.reshape(1,HiddenLayerNeurons))\n",
        "  gradient_output_weights = np.dot(hiddenlayer.reshape(HiddenLayerNeurons,1),error_terms_output.reshape(1,outputNeurons))\n",
        "\n",
        "  hiddenweights = hiddenweights+ 0.5*gradient_hidden_weights\n",
        "  outputweights = outputweights + 0.5*gradient_output_weights\n",
        "\n",
        "  if i<50 or i>iteration-50:\n",
        "    print(\"**************\")\n",
        "    print(\"iteration\",i,\"::::::;;\",error)\n",
        "    print(\"#######output######\",outputlayer)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fE6R34AegVT",
        "outputId": "02dab7d6-36c5-4d77-a1bb-bdb193c81ad1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************\n",
            "iteration 0 ::::::;; [[ 0.06521996 -0.87245407]]\n",
            "#######output###### [[0.93478004 0.87245407]]\n",
            "**************\n",
            "iteration 1 ::::::;; [[ 0.06518509 -0.8528409 ]]\n",
            "#######output###### [[0.93481491 0.8528409 ]]\n",
            "**************\n",
            "iteration 2 ::::::;; [[ 0.06517497 -0.82859341]]\n",
            "#######output###### [[0.93482503 0.82859341]]\n",
            "**************\n",
            "iteration 3 ::::::;; [[ 0.06518146 -0.79865477]]\n",
            "#######output###### [[0.93481854 0.79865477]]\n",
            "**************\n",
            "iteration 4 ::::::;; [[ 0.06519011 -0.7620389 ]]\n",
            "#######output###### [[0.93480989 0.7620389 ]]\n",
            "**************\n",
            "iteration 5 ::::::;; [[ 0.06517895 -0.71819843]]\n",
            "#######output###### [[0.93482105 0.71819843]]\n",
            "**************\n",
            "iteration 6 ::::::;; [[ 0.06511981 -0.66756672]]\n",
            "#######output###### [[0.93488019 0.66756672]]\n",
            "**************\n",
            "iteration 7 ::::::;; [[ 0.06498423 -0.61202439]]\n",
            "#######output###### [[0.93501577 0.61202439]]\n",
            "**************\n",
            "iteration 8 ::::::;; [[ 0.06475323 -0.55480355]]\n",
            "#######output###### [[0.93524677 0.55480355]]\n",
            "**************\n",
            "iteration 9 ::::::;; [[ 0.06442533 -0.49956962]]\n",
            "#######output###### [[0.93557467 0.49956962]]\n",
            "**************\n",
            "iteration 10 ::::::;; [[ 0.06401613 -0.44919655]]\n",
            "#######output###### [[0.93598387 0.44919655]]\n",
            "**************\n",
            "iteration 11 ::::::;; [[ 0.06354996 -0.40511445]]\n",
            "#######output###### [[0.93645004 0.40511445]]\n",
            "**************\n",
            "iteration 12 ::::::;; [[ 0.06305074 -0.36747327]]\n",
            "#######output###### [[0.93694926 0.36747327]]\n",
            "**************\n",
            "iteration 13 ::::::;; [[ 0.06253709 -0.33568031]]\n",
            "#######output###### [[0.93746291 0.33568031]]\n",
            "**************\n",
            "iteration 14 ::::::;; [[ 0.06202159 -0.30887052]]\n",
            "#######output###### [[0.93797841 0.30887052]]\n",
            "**************\n",
            "iteration 15 ::::::;; [[ 0.06151199 -0.28617492]]\n",
            "#######output###### [[0.93848801 0.28617492]]\n",
            "**************\n",
            "iteration 16 ::::::;; [[ 0.06101266 -0.26683165]]\n",
            "#######output###### [[0.93898734 0.26683165]]\n",
            "**************\n",
            "iteration 17 ::::::;; [[ 0.06052588 -0.2502125 ]]\n",
            "#######output###### [[0.93947412 0.2502125 ]]\n",
            "**************\n",
            "iteration 18 ::::::;; [[ 0.06005262 -0.23581378]]\n",
            "#######output###### [[0.93994738 0.23581378]]\n",
            "**************\n",
            "iteration 19 ::::::;; [[ 0.0595931 -0.223236 ]]\n",
            "#######output###### [[0.9404069 0.223236 ]]\n",
            "**************\n",
            "iteration 20 ::::::;; [[ 0.0591471  -0.21216292]]\n",
            "#######output###### [[0.9408529  0.21216292]]\n",
            "**************\n",
            "iteration 21 ::::::;; [[ 0.05871417 -0.20234343]]\n",
            "#######output###### [[0.94128583 0.20234343]]\n",
            "**************\n",
            "iteration 22 ::::::;; [[ 0.05829375 -0.19357695]]\n",
            "#######output###### [[0.94170625 0.19357695]]\n",
            "**************\n",
            "iteration 23 ::::::;; [[ 0.05788523 -0.18570214]]\n",
            "#######output###### [[0.94211477 0.18570214]]\n",
            "**************\n",
            "iteration 24 ::::::;; [[ 0.05748799 -0.1785882 ]]\n",
            "#######output###### [[0.94251201 0.1785882 ]]\n",
            "**************\n",
            "iteration 25 ::::::;; [[ 0.05710144 -0.17212823]]\n",
            "#######output###### [[0.94289856 0.17212823]]\n",
            "**************\n",
            "iteration 26 ::::::;; [[ 0.05672499 -0.16623418]]\n",
            "#######output###### [[0.94327501 0.16623418]]\n",
            "**************\n",
            "iteration 27 ::::::;; [[ 0.05635812 -0.160833  ]]\n",
            "#######output###### [[0.94364188 0.160833  ]]\n",
            "**************\n",
            "iteration 28 ::::::;; [[ 0.05600033 -0.1558636 ]]\n",
            "#######output###### [[0.94399967 0.1558636 ]]\n",
            "**************\n",
            "iteration 29 ::::::;; [[ 0.05565113 -0.15127455]]\n",
            "#######output###### [[0.94434887 0.15127455]]\n",
            "**************\n",
            "iteration 30 ::::::;; [[ 0.05531011 -0.14702231]]\n",
            "#######output###### [[0.94468989 0.14702231]]\n",
            "**************\n",
            "iteration 31 ::::::;; [[ 0.05497687 -0.14306971]]\n",
            "#######output###### [[0.94502313 0.14306971]]\n",
            "**************\n",
            "iteration 32 ::::::;; [[ 0.05465101 -0.13938492]]\n",
            "#######output###### [[0.94534899 0.13938492]]\n",
            "**************\n",
            "iteration 33 ::::::;; [[ 0.05433222 -0.13594046]]\n",
            "#######output###### [[0.94566778 0.13594046]]\n",
            "**************\n",
            "iteration 34 ::::::;; [[ 0.05402016 -0.13271254]]\n",
            "#######output###### [[0.94597984 0.13271254]]\n",
            "**************\n",
            "iteration 35 ::::::;; [[ 0.05371454 -0.12968041]]\n",
            "#######output###### [[0.94628546 0.12968041]]\n",
            "**************\n",
            "iteration 36 ::::::;; [[ 0.05341508 -0.12682595]]\n",
            "#######output###### [[0.94658492 0.12682595]]\n",
            "**************\n",
            "iteration 37 ::::::;; [[ 0.05312153 -0.12413321]]\n",
            "#######output###### [[0.94687847 0.12413321]]\n",
            "**************\n",
            "iteration 38 ::::::;; [[ 0.05283364 -0.12158814]]\n",
            "#######output###### [[0.94716636 0.12158814]]\n",
            "**************\n",
            "iteration 39 ::::::;; [[ 0.0525512  -0.11917827]]\n",
            "#######output###### [[0.9474488  0.11917827]]\n",
            "**************\n",
            "iteration 40 ::::::;; [[ 0.05227399 -0.11689253]]\n",
            "#######output###### [[0.94772601 0.11689253]]\n",
            "**************\n",
            "iteration 41 ::::::;; [[ 0.05200182 -0.11472106]]\n",
            "#######output###### [[0.94799818 0.11472106]]\n",
            "**************\n",
            "iteration 42 ::::::;; [[ 0.05173449 -0.11265501]]\n",
            "#######output###### [[0.94826551 0.11265501]]\n",
            "**************\n",
            "iteration 43 ::::::;; [[ 0.05147185 -0.11068646]]\n",
            "#######output###### [[0.94852815 0.11068646]]\n",
            "**************\n",
            "iteration 44 ::::::;; [[ 0.05121372 -0.10880825]]\n",
            "#######output###### [[0.94878628 0.10880825]]\n",
            "**************\n",
            "iteration 45 ::::::;; [[ 0.05095995 -0.10701395]]\n",
            "#######output###### [[0.94904005 0.10701395]]\n",
            "**************\n",
            "iteration 46 ::::::;; [[ 0.0507104  -0.10529771]]\n",
            "#######output###### [[0.9492896  0.10529771]]\n",
            "**************\n",
            "iteration 47 ::::::;; [[ 0.05046492 -0.10365425]]\n",
            "#######output###### [[0.94953508 0.10365425]]\n",
            "**************\n",
            "iteration 48 ::::::;; [[ 0.05022339 -0.10207874]]\n",
            "#######output###### [[0.94977661 0.10207874]]\n",
            "**************\n",
            "iteration 49 ::::::;; [[ 0.04998569 -0.10056679]]\n",
            "#######output###### [[0.95001431 0.10056679]]\n",
            "**************\n",
            "iteration 5951 ::::::;; [[ 0.00660319 -0.00665566]]\n",
            "#######output###### [[0.99339681 0.00665566]]\n",
            "**************\n",
            "iteration 5952 ::::::;; [[ 0.00660263 -0.00665509]]\n",
            "#######output###### [[0.99339737 0.00665509]]\n",
            "**************\n",
            "iteration 5953 ::::::;; [[ 0.00660208 -0.00665451]]\n",
            "#######output###### [[0.99339792 0.00665451]]\n",
            "**************\n",
            "iteration 5954 ::::::;; [[ 0.00660152 -0.00665394]]\n",
            "#######output###### [[0.99339848 0.00665394]]\n",
            "**************\n",
            "iteration 5955 ::::::;; [[ 0.00660096 -0.00665337]]\n",
            "#######output###### [[0.99339904 0.00665337]]\n",
            "**************\n",
            "iteration 5956 ::::::;; [[ 0.00660041 -0.0066528 ]]\n",
            "#######output###### [[0.99339959 0.0066528 ]]\n",
            "**************\n",
            "iteration 5957 ::::::;; [[ 0.00659985 -0.00665223]]\n",
            "#######output###### [[0.99340015 0.00665223]]\n",
            "**************\n",
            "iteration 5958 ::::::;; [[ 0.0065993  -0.00665166]]\n",
            "#######output###### [[0.9934007  0.00665166]]\n",
            "**************\n",
            "iteration 5959 ::::::;; [[ 0.00659874 -0.00665108]]\n",
            "#######output###### [[0.99340126 0.00665108]]\n",
            "**************\n",
            "iteration 5960 ::::::;; [[ 0.00659818 -0.00665051]]\n",
            "#######output###### [[0.99340182 0.00665051]]\n",
            "**************\n",
            "iteration 5961 ::::::;; [[ 0.00659763 -0.00664994]]\n",
            "#######output###### [[0.99340237 0.00664994]]\n",
            "**************\n",
            "iteration 5962 ::::::;; [[ 0.00659707 -0.00664937]]\n",
            "#######output###### [[0.99340293 0.00664937]]\n",
            "**************\n",
            "iteration 5963 ::::::;; [[ 0.00659652 -0.0066488 ]]\n",
            "#######output###### [[0.99340348 0.0066488 ]]\n",
            "**************\n",
            "iteration 5964 ::::::;; [[ 0.00659596 -0.00664823]]\n",
            "#######output###### [[0.99340404 0.00664823]]\n",
            "**************\n",
            "iteration 5965 ::::::;; [[ 0.00659541 -0.00664766]]\n",
            "#######output###### [[0.99340459 0.00664766]]\n",
            "**************\n",
            "iteration 5966 ::::::;; [[ 0.00659485 -0.00664709]]\n",
            "#######output###### [[0.99340515 0.00664709]]\n",
            "**************\n",
            "iteration 5967 ::::::;; [[ 0.0065943  -0.00664652]]\n",
            "#######output###### [[0.9934057  0.00664652]]\n",
            "**************\n",
            "iteration 5968 ::::::;; [[ 0.00659375 -0.00664595]]\n",
            "#######output###### [[0.99340625 0.00664595]]\n",
            "**************\n",
            "iteration 5969 ::::::;; [[ 0.00659319 -0.00664538]]\n",
            "#######output###### [[0.99340681 0.00664538]]\n",
            "**************\n",
            "iteration 5970 ::::::;; [[ 0.00659264 -0.00664481]]\n",
            "#######output###### [[0.99340736 0.00664481]]\n",
            "**************\n",
            "iteration 5971 ::::::;; [[ 0.00659208 -0.00664424]]\n",
            "#######output###### [[0.99340792 0.00664424]]\n",
            "**************\n",
            "iteration 5972 ::::::;; [[ 0.00659153 -0.00664367]]\n",
            "#######output###### [[0.99340847 0.00664367]]\n",
            "**************\n",
            "iteration 5973 ::::::;; [[ 0.00659098 -0.0066431 ]]\n",
            "#######output###### [[0.99340902 0.0066431 ]]\n",
            "**************\n",
            "iteration 5974 ::::::;; [[ 0.00659042 -0.00664253]]\n",
            "#######output###### [[0.99340958 0.00664253]]\n",
            "**************\n",
            "iteration 5975 ::::::;; [[ 0.00658987 -0.00664196]]\n",
            "#######output###### [[0.99341013 0.00664196]]\n",
            "**************\n",
            "iteration 5976 ::::::;; [[ 0.00658931 -0.00664139]]\n",
            "#######output###### [[0.99341069 0.00664139]]\n",
            "**************\n",
            "iteration 5977 ::::::;; [[ 0.00658876 -0.00664082]]\n",
            "#######output###### [[0.99341124 0.00664082]]\n",
            "**************\n",
            "iteration 5978 ::::::;; [[ 0.00658821 -0.00664025]]\n",
            "#######output###### [[0.99341179 0.00664025]]\n",
            "**************\n",
            "iteration 5979 ::::::;; [[ 0.00658766 -0.00663968]]\n",
            "#######output###### [[0.99341234 0.00663968]]\n",
            "**************\n",
            "iteration 5980 ::::::;; [[ 0.0065871  -0.00663912]]\n",
            "#######output###### [[0.9934129  0.00663912]]\n",
            "**************\n",
            "iteration 5981 ::::::;; [[ 0.00658655 -0.00663855]]\n",
            "#######output###### [[0.99341345 0.00663855]]\n",
            "**************\n",
            "iteration 5982 ::::::;; [[ 0.006586   -0.00663798]]\n",
            "#######output###### [[0.993414   0.00663798]]\n",
            "**************\n",
            "iteration 5983 ::::::;; [[ 0.00658545 -0.00663741]]\n",
            "#######output###### [[0.99341455 0.00663741]]\n",
            "**************\n",
            "iteration 5984 ::::::;; [[ 0.00658489 -0.00663684]]\n",
            "#######output###### [[0.99341511 0.00663684]]\n",
            "**************\n",
            "iteration 5985 ::::::;; [[ 0.00658434 -0.00663628]]\n",
            "#######output###### [[0.99341566 0.00663628]]\n",
            "**************\n",
            "iteration 5986 ::::::;; [[ 0.00658379 -0.00663571]]\n",
            "#######output###### [[0.99341621 0.00663571]]\n",
            "**************\n",
            "iteration 5987 ::::::;; [[ 0.00658324 -0.00663514]]\n",
            "#######output###### [[0.99341676 0.00663514]]\n",
            "**************\n",
            "iteration 5988 ::::::;; [[ 0.00658269 -0.00663457]]\n",
            "#######output###### [[0.99341731 0.00663457]]\n",
            "**************\n",
            "iteration 5989 ::::::;; [[ 0.00658213 -0.00663401]]\n",
            "#######output###### [[0.99341787 0.00663401]]\n",
            "**************\n",
            "iteration 5990 ::::::;; [[ 0.00658158 -0.00663344]]\n",
            "#######output###### [[0.99341842 0.00663344]]\n",
            "**************\n",
            "iteration 5991 ::::::;; [[ 0.00658103 -0.00663287]]\n",
            "#######output###### [[0.99341897 0.00663287]]\n",
            "**************\n",
            "iteration 5992 ::::::;; [[ 0.00658048 -0.00663231]]\n",
            "#######output###### [[0.99341952 0.00663231]]\n",
            "**************\n",
            "iteration 5993 ::::::;; [[ 0.00657993 -0.00663174]]\n",
            "#######output###### [[0.99342007 0.00663174]]\n",
            "**************\n",
            "iteration 5994 ::::::;; [[ 0.00657938 -0.00663117]]\n",
            "#######output###### [[0.99342062 0.00663117]]\n",
            "**************\n",
            "iteration 5995 ::::::;; [[ 0.00657883 -0.00663061]]\n",
            "#######output###### [[0.99342117 0.00663061]]\n",
            "**************\n",
            "iteration 5996 ::::::;; [[ 0.00657828 -0.00663004]]\n",
            "#######output###### [[0.99342172 0.00663004]]\n",
            "**************\n",
            "iteration 5997 ::::::;; [[ 0.00657773 -0.00662947]]\n",
            "#######output###### [[0.99342227 0.00662947]]\n",
            "**************\n",
            "iteration 5998 ::::::;; [[ 0.00657718 -0.00662891]]\n",
            "#######output###### [[0.99342282 0.00662891]]\n",
            "**************\n",
            "iteration 5999 ::::::;; [[ 0.00657663 -0.00662834]]\n",
            "#######output###### [[0.99342337 0.00662834]]\n"
          ]
        }
      ]
    }
  ]
}